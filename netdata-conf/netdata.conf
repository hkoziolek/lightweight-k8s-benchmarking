# netdata configuration
#
# You can download the latest version of this file, using:
#
#  wget -O /etc/netdata/netdata.conf http://localhost:19999/netdata.conf
# or
#  curl -o /etc/netdata/netdata.conf http://localhost:19999/netdata.conf
#
# You can uncomment and change any of the options below.
# The value shown in the commented settings, is the default value.
#

# global netdata configuration

[global]
	# run as user = netdata
	# glibc malloc arena max for plugins = 1
	# glibc malloc arena max for netdata = 1
	# libuv worker threads = 16
	# hostname = pluto
	# host access prefix = 
	# enable metric correlations = yes
	# metric correlations method = ks2
	# timezone = Etc/UTC
	# OOM score = 0
	# process scheduling policy = batch
	# process nice level = 19
	# pthread stack size = 8388608

[db]
	# update every = 1
	# mode = dbengine
	# dbengine page cache with malloc = no
	# dbengine page cache size MB = 32
	# dbengine disk space MB = 256
	# dbengine multihost disk space MB = 256
	# memory deduplication (ksm) = yes
	# cleanup obsolete charts after secs = 3600
	# gap when lost iterations above = 1
	# storage tiers = 1
	# dbengine page fetch timeout secs = 3
	# dbengine page fetch retries = 3
	# dbengine page descriptors in file mapped memory = no
	# cleanup orphan hosts after secs = 3600
	# delete obsolete charts files = yes
	# delete orphan hosts files = yes
	# enable zero metrics = no
	# dbengine pages per extent = 64

[directories]
	# config = /etc/netdata
	# stock config = /usr/lib/netdata/conf.d
	# log = /var/log/netdata
	# web = /usr/share/netdata/web
	# cache = /var/cache/netdata
	# lib = /var/lib/netdata
	# home = /var/lib/netdata
	# lock = /var/lib/netdata/lock
	# plugins = "/usr/libexec/netdata/plugins.d" "/etc/netdata/custom-plugins.d"
	# registry = /var/lib/netdata/registry
	# stock health config = /usr/lib/netdata/conf.d/health.d
	# health config = /etc/netdata/health.d

[logs]
	# debug flags = 0x0000000000000000
	# debug = /var/log/netdata/debug.log
	# error = /var/log/netdata/error.log
	# access = /var/log/netdata/access.log
	# facility = daemon
	# errors flood protection period = 1200
	# errors to trigger flood protection = 200

[environment variables]
	# PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin
	# PYTHONPATH = 
	# TZ = :/etc/localtime

[host labels]
	# name = value

[sqlite]
	# auto vacuum = INCREMENTAL
	# synchronous = NORMAL
	# journal mode = WAL
	# temp store = MEMORY
	# journal size limit = 16777216
	# cache size = -2000

[cloud]
	# rrdcontexts = yes
	# conversation log = no
	# proxy = env
	# mqtt5 = yes
	# query thread count = 2

[ml]
	# enabled = yes
	# maximum num samples to train = 14400
	# minimum num samples to train = 900
	# train every = 3600
	# dbengine anomaly rate every = 30
	# num samples to diff = 1
	# num samples to smooth = 3
	# num samples to lag = 5
	# random sampling ratio = 0.20000
	# maximum number of k-means iterations = 1000
	# dimension anomaly score threshold = 0.99000
	# host anomaly rate threshold = 0.01000
	# minimum window size = 30.00000
	# maximum window size = 600.00000
	# idle window size = 30.00000
	# window minimum anomaly rate = 0.25000
	# anomaly event min dimension rate threshold = 0.05000
	# hosts to skip from training = !*
	# charts to skip from training = netdata.*
	# stream anomaly detection charts = yes

[health]
	# silencers file = /var/lib/netdata/health.silencers.json
	# enabled = yes
	# default repeat warning = never
	# default repeat critical = never
	# in memory max health log entries = 1000
	# script to execute on alarm = /usr/libexec/netdata/plugins.d/alarm-notify.sh
	# enable stock health configuration = yes
	# rotate log every lines = 2000
	# run at least every seconds = 10
	# postpone alarms during hibernation for seconds = 60

[web]
	# ssl key = /etc/netdata/ssl/key.pem
	# ssl certificate = /etc/netdata/ssl/cert.pem
	# tls version = 1.3
	# tls ciphers = none
	# ses max window = 15
	# des max window = 15
	# mode = static-threaded
	# listen backlog = 4096
	# default port = 19999
	# bind to = *
	# disconnect idle clients after seconds = 60
	# timeout for first request = 60
	# accept a streaming request every seconds = 0
	# respect do not track policy = no
	# x-frame-options response header = 
	# allow connections from = localhost *
	# allow connections by dns = heuristic
	# allow dashboard from = localhost *
	# allow dashboard by dns = heuristic
	# allow badges from = *
	# allow badges by dns = heuristic
	# allow streaming from = *
	# allow streaming by dns = heuristic
	# allow netdata.conf from = localhost fd* 10.* 192.168.* 172.16.* 172.17.* 172.18.* 172.19.* 172.20.* 172.21.* 172.22.* 172.23.* 172.24.* 172.25.* 172.26.* 172.27.* 172.28.* 172.29.* 172.30.* 172.31.* UNKNOWN
	# allow netdata.conf by dns = no
	# allow management from = localhost
	# allow management by dns = heuristic
	# enable gzip compression = yes
	# gzip compression strategy = default
	# gzip compression level = 3
	# web server threads = 2
	# web server max sockets = 256

[registry]
	# enabled = no
	# netdata unique id file = /var/lib/netdata/registry/netdata.public.unique.id
	# registry db file = /var/lib/netdata/registry/registry.db
	# registry log file = /var/lib/netdata/registry/registry-log.db
	# registry save db every new entries = 1000000
	# registry expire idle persons days = 365
	# registry domain = 
	# registry to announce = https://registry.my-netdata.io
	# registry hostname = pluto
	# verify browser cookies support = yes
	# enable cookies SameSite and Secure = yes
	# max URL length = 1024
	# max URL name length = 50
	# netdata management api key file = /var/lib/netdata/netdata.api.key
	# allow from = *
	# allow by dns = heuristic

[global statistics]
	# update every = 1

[plugins]
	# timex = yes
	# checks = no
	# idlejitter = yes
	# tc = yes
	# diskspace = yes
	# proc = yes
	# cgroups = yes
	# statsd = yes
	# enable running new plugins = yes
	# check for new plugins every = 60
	# slabinfo = no
	# charts.d = yes
	# perf = yes
	# ebpf = yes
	# apps = yes
	# python.d = yes
	# go.d = yes
	# ioping = yes
	# fping = yes

[statsd]
	# update every (flushInterval) = 1
	# udp messages to process at once = 10
	# create private charts for metrics matching = *
	# max private charts hard limit = 1000
	# private charts history = 3600
	# decimal detail = 1000
	# disconnect idle tcp clients after seconds = 600
	# private charts hidden = no
	# histograms and timers percentile (percentThreshold) = 95.00000
	# dictionaries max unique dimensions = 200
	# add dimension for number of events received = no
	# gaps on gauges (deleteGauges) = no
	# gaps on counters (deleteCounters) = no
	# gaps on meters (deleteMeters) = no
	# gaps on sets (deleteSets) = no
	# gaps on histograms (deleteHistograms) = no
	# gaps on timers (deleteTimers) = no
	# gaps on dictionaries (deleteDictionaries) = no
	# statsd server max TCP sockets = 256
	# listen backlog = 4096
	# default port = 8125
	# bind to = udp:localhost tcp:localhost

[plugin:timex]
	# update every = 10
	# clock synchronization state = yes
	# time offset = yes

[plugin:idlejitter]
	# loop time in ms = 20

[plugin:cgroups]
	# update every = 1
	# check for new cgroups every = 10
	# use unified cgroups = auto
	# containers priority = 40000
	# enable cpuacct stat (total CPU) = auto
	# enable cpuacct usage (per core CPU) = auto
	# enable cpuacct cpu throttling = yes
	# enable cpuacct cpu shares = no
	# enable memory = auto
	# enable detailed memory = auto
	# enable memory limits fail count = auto
	# enable swap memory = auto
	# enable blkio bandwidth = auto
	# enable blkio operations = auto
	# enable blkio throttle bandwidth = auto
	# enable blkio throttle operations = auto
	# enable blkio queued operations = auto
	# enable blkio merged operations = auto
	# enable cpu pressure = auto
	# enable io some pressure = auto
	# enable io full pressure = auto
	# enable memory some pressure = auto
	# enable memory full pressure = auto
	# recheck zero blkio every iterations = 10
	# recheck zero memory failcnt every iterations = 10
	# recheck zero detailed memory every iterations = 10
	# enable systemd services = yes
	# enable systemd services detailed memory = no
	# report used memory = yes
	# path to /sys/fs/cgroup/cpuacct = /sys/fs/cgroup/cpu,cpuacct
	# path to /sys/fs/cgroup/cpuset = /sys/fs/cgroup/cpuset
	# path to /sys/fs/cgroup/blkio = /sys/fs/cgroup/blkio
	# path to /sys/fs/cgroup/memory = /sys/fs/cgroup/memory
	# path to /sys/fs/cgroup/devices = /sys/fs/cgroup/devices
	# max cgroups to allow = 1000
	# max cgroups depth to monitor = 0
	# enable by default cgroups matching =  !*/init.scope  !/system.slice/run-*.scope  *.scope  /machine.slice/*.service  */kubepods/pod*/*  */kubepods/*/pod*/*  */*-kubepods-pod*/*  */*-kubepods-*-pod*/*  !*kubepods* !*kubelet*  !*/vcpu*  !*/emulator  !*.mount  !*.partition  !*.service  !*.socket  !*.slice  !*.swap  !*.user  !/  !/docker  !*/libvirt  !/lxc  !/lxc/*/*  !/lxc.monitor*  !/lxc.pivot  !/lxc.payload  !/machine  !/qemu  !/system  !/systemd  !/user  * 
	# enable by default cgroups names matching =  * 
	# search for cgroups in subpaths matching =  !*/init.scope  !*-qemu  !*.libvirt-qemu  !/init.scope  !/system  !/systemd  !/user  !/user.slice  !/lxc/*/*  !/lxc.monitor  !/lxc.payload/*/*  !/lxc.payload.*  * 
	# script to get cgroup names = /usr/libexec/netdata/plugins.d/cgroup-name.sh
	# script to get cgroup network interfaces = /usr/libexec/netdata/plugins.d/cgroup-network
	# run script to rename cgroups matching =  !/  !*.mount  !*.socket  !*.partition  /machine.slice/*.service  !*.service  !*.slice  !*.swap  !*.user  !init.scope  !*.scope/vcpu*  !*.scope/emulator  *.scope  *docker*  *lxc*  *qemu*  */kubepods/pod*/*  */kubepods/*/pod*/*  */*-kubepods-pod*/*  */*-kubepods-*-pod*/*  !*kubepods* !*kubelet*  *.libvirt-qemu  * 
	# cgroups to match as systemd services =  !/system.slice/*/*.service  /system.slice/*.service 
	# meminfo filename to monitor = /proc/meminfo

[plugin:proc]
	# /proc/net/dev = yes
	# /proc/pagetypeinfo = no
	# /proc/stat = yes
	# /proc/uptime = yes
	# /proc/loadavg = yes
	# /proc/sys/kernel/random/entropy_avail = yes
	# /proc/pressure = yes
	# /proc/interrupts = yes
	# /proc/softirqs = yes
	# /proc/vmstat = yes
	# /proc/meminfo = yes
	# /sys/kernel/mm/ksm = yes
	# /sys/block/zram = yes
	# /sys/devices/system/edac/mc = yes
	# /sys/devices/system/node = yes
	# /proc/net/wireless = yes
	# /proc/net/sockstat = yes
	# /proc/net/sockstat6 = yes
	# /proc/net/netstat = yes
	# /proc/net/snmp = yes
	# /proc/net/snmp6 = yes
	# /proc/net/sctp/snmp = yes
	# /proc/net/softnet_stat = yes
	# /proc/net/ip_vs/stats = yes
	# /sys/class/infiniband = yes
	# /proc/net/stat/conntrack = yes
	# /proc/net/stat/synproxy = yes
	# /proc/diskstats = yes
	# /proc/mdstat = yes
	# /proc/net/rpc/nfsd = yes
	# /proc/net/rpc/nfs = yes
	# /proc/spl/kstat/zfs/arcstats = yes
	# /proc/spl/kstat/zfs/pool/state = yes
	# /sys/fs/btrfs = yes
	# ipc = yes
	# /sys/class/power_supply = yes

[plugin:charts.d]
	# update every = 1
	# command options = 

[plugin:perf]
	# update every = 1
	# command options = 

[plugin:ebpf]
	# update every = 1
	# command options = 

[plugin:apps]
	# update every = 1
	# command options = 

[plugin:python.d]
	# update every = 1
	# command options = 

[plugin:go.d]
	# update every = 1
	# command options = 

[plugin:ioping]
	# update every = 1
	# command options = 

[plugin:fping]
	# update every = 1
	# command options = 

[plugin:tc]
	# script to run to get tc values = /usr/libexec/netdata/plugins.d/tc-qos-helper.sh
	# enable new interfaces detected at runtime = yes
	# enable traffic charts for all interfaces = auto
	# enable packets charts for all interfaces = auto
	# enable dropped charts for all interfaces = auto
	# enable tokens charts for all interfaces = no
	# enable ctokens charts for all interfaces = no
	# enable show all classes and qdiscs for all interfaces = no
	# qos for eth0 = yes
	# traffic chart for eth0 = auto
	# packets chart for eth0 = auto
	# dropped packets chart for eth0 = auto
	# tokens chart for eth0 = no
	# ctokens chart for eth0 = no
	# show all classes for eth0 = no
	# cleanup unused classes every = 120
	# qos for enP22971s1 = yes
	# traffic chart for enP22971s1 = auto
	# packets chart for enP22971s1 = auto
	# dropped packets chart for enP22971s1 = auto
	# tokens chart for enP22971s1 = no
	# ctokens chart for enP22971s1 = no
	# show all classes for enP22971s1 = no

[plugin:proc:diskspace]
	# remove charts of unmounted disks = yes
	# update every = 1
	# check for new mount points every = 15
	# exclude space metrics on paths = /proc/* /sys/* /var/run/user/* /run/user/* /snap/* /var/lib/docker/*
	# exclude space metrics on filesystems = *gvfs *gluster* *s3fs *ipfs *davfs2 *httpfs *sshfs *gdfs *moosefs fusectl autofs
	# space usage for all disks = auto
	# inodes usage for all disks = auto

[plugin:proc:/proc/net/dev]
	# filename to monitor = /proc/net/dev
	# path to get virtual interfaces = /sys/devices/virtual/net/%s
	# path to get net device speed = /sys/class/net/%s/speed
	# path to get net device duplex = /sys/class/net/%s/duplex
	# path to get net device operstate = /sys/class/net/%s/operstate
	# path to get net device carrier = /sys/class/net/%s/carrier
	# path to get net device mtu = /sys/class/net/%s/mtu
	# enable new interfaces detected at runtime = auto
	# bandwidth for all interfaces = auto
	# packets for all interfaces = auto
	# errors for all interfaces = auto
	# drops for all interfaces = auto
	# fifo for all interfaces = auto
	# compressed packets for all interfaces = auto
	# frames, collisions, carrier counters for all interfaces = auto
	# speed for all interfaces = auto
	# duplex for all interfaces = auto
	# operstate for all interfaces = auto
	# carrier for all interfaces = auto
	# mtu for all interfaces = auto
	# disable by default interfaces matching = lo fireqos* *-ifb fwpr* fwbr* fwln*

[plugin:proc:/proc/net/dev:lo]
	# enabled = no
	# virtual = yes

[plugin:proc:/proc/net/dev:eth0]
	# enabled = yes
	# virtual = no
	# bandwidth = auto
	# packets = auto
	# errors = auto
	# drops = auto
	# fifo = auto
	# compressed = auto
	# events = auto
	# speed = auto
	# duplex = auto
	# operstate = auto
	# carrier = auto
	# mtu = auto

[plugin:proc:/proc/net/dev:enP22971s1]
	# enabled = yes
	# virtual = no
	# bandwidth = auto
	# packets = auto
	# errors = auto
	# drops = auto
	# fifo = auto
	# compressed = auto
	# events = auto
	# speed = auto
	# duplex = auto
	# operstate = auto
	# carrier = auto
	# mtu = auto

[plugin:proc:/proc/stat]
	# cpu utilization = yes
	# per cpu core utilization = yes
	# cpu interrupts = yes
	# context switches = yes
	# processes started = yes
	# processes running = yes
	# keep per core files open = yes
	# keep cpuidle files open = yes
	# core_throttle_count = auto
	# package_throttle_count = no
	# cpu frequency = yes
	# cpu idle states = yes
	# core_throttle_count filename to monitor = /sys/devices/system/cpu/%s/thermal_throttle/core_throttle_count
	# package_throttle_count filename to monitor = /sys/devices/system/cpu/%s/thermal_throttle/package_throttle_count
	# scaling_cur_freq filename to monitor = /sys/devices/system/cpu/%s/cpufreq/scaling_cur_freq
	# time_in_state filename to monitor = /sys/devices/system/cpu/%s/cpufreq/stats/time_in_state
	# schedstat filename to monitor = /proc/schedstat
	# cpuidle name filename to monitor = /sys/devices/system/cpu/cpu%zu/cpuidle/state%zu/name
	# cpuidle time filename to monitor = /sys/devices/system/cpu/cpu%zu/cpuidle/state%zu/time
	# filename to monitor = /proc/stat

[plugin:proc:/proc/net/dev:cali047124df17b]
	# enabled = yes
	# virtual = yes
	# bandwidth = auto
	# packets = auto
	# errors = auto
	# drops = auto
	# fifo = auto
	# compressed = auto
	# events = auto
	# speed = auto
	# duplex = auto
	# operstate = auto
	# carrier = auto
	# mtu = auto

[plugin:proc:/proc/net/dev:cali96c94df6594]
	# enabled = yes
	# virtual = yes
	# bandwidth = auto
	# packets = auto
	# errors = auto
	# drops = auto
	# fifo = auto
	# compressed = auto
	# events = auto
	# speed = auto
	# duplex = auto
	# operstate = auto
	# carrier = auto
	# mtu = auto

[plugin:proc:/proc/uptime]
	# filename to monitor = /proc/uptime

[plugin:proc:/proc/loadavg]
	# filename to monitor = /proc/loadavg
	# enable load average = yes
	# enable total processes = yes

[plugin:proc:/proc/sys/kernel/random/entropy_avail]
	# filename to monitor = /proc/sys/kernel/random/entropy_avail

[plugin:proc:/proc/pressure]
	# base path of pressure metrics = /proc/pressure
	# enable cpu some pressure = yes
	# enable cpu full pressure = yes
	# enable memory some pressure = yes
	# enable memory full pressure = yes
	# enable io some pressure = yes
	# enable io full pressure = yes

[plugin:proc:diskspace:/]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/dev]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:/proc/net/dev:cali3d926bb4b1b]
	# enabled = yes
	# virtual = yes
	# bandwidth = auto
	# packets = auto
	# errors = auto
	# drops = auto
	# fifo = auto
	# compressed = auto
	# events = auto
	# speed = auto
	# duplex = auto
	# operstate = auto
	# carrier = auto
	# mtu = auto

[plugin:proc:/proc/interrupts]
	# interrupts per core = auto
	# filename to monitor = /proc/interrupts

[plugin:proc:diskspace:/dev/shm]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/dev/hugepages]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/sys/kernel/security]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/unified]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/systemd]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/rdma]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/blkio]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/cpuset]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/misc]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/devices]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/net_cls,net_prio]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/perf_event]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/cpu,cpuacct]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/memory]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/freezer]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/hugetlb]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/cgroup/pids]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/pstore]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/firmware/efi/efivars]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/fs/bpf]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/kernel/tracing]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/sys/kernel/config]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/run]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:/proc/net/dev:vxlan.calico]
	# enabled = yes
	# virtual = yes
	# bandwidth = auto
	# packets = auto
	# errors = auto
	# drops = auto
	# fifo = auto
	# compressed = auto
	# events = auto
	# speed = auto
	# duplex = auto
	# operstate = auto
	# carrier = auto
	# mtu = auto

[plugin:proc:diskspace:/run/lock]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/run/snapd/ns]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:/proc/softirqs]
	# interrupts per core = auto
	# filename to monitor = /proc/softirqs

[plugin:proc:diskspace:/run/netns/cni-8feeb8cd-8d56-b546-6bd4-0328955c2e96]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/run/netns/cni-c8f00f84-a15e-1c7f-1fbf-29d2240b3c85]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/run/netns/cni-e3a25c29-645d-292a-8329-3b708e36a99b]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/run/user/1000]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/snap/lxd/22753]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/snap/core18/2560]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/snap/microk8s/3597]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/snap/snapd/16292]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/snap/core20/1611]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/boot/efi]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/mnt]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/snap/core20/1623]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/var/lib/kubelet/pods/04d7f31e-01e8-4e63-a748-f56a30590531/volumes/kubernetes.io~projected/kube-api-access-rqv8p]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/var/lib/kubelet/pods/64e86595-bffe-41ad-82d8-8a0594d2b93e/volumes/kubernetes.io~projected/kube-api-access-sdrbn]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/var/lib/kubelet/pods/27bdfa0f-e3c0-4246-bc3a-d1b54bb70931/volumes/kubernetes.io~projected/kube-api-access-jwbzs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.grpc.v1.cri/sandboxes/96c08affc86bfc83a6788eefbbc8eec1d6e16de9f453bf63bf01ef6944be3d3f/shm]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:/proc/vmstat]
	# filename to monitor = /proc/vmstat
	# swap i/o = auto
	# disk i/o = yes
	# memory page faults = yes
	# out of memory kills = yes
	# system-wide numa metric summary = auto

[plugin:proc:/sys/devices/system/node]
	# directory to monitor = /sys/devices/system/node
	# enable per-node numa metrics = auto

[plugin:proc:diskspace:/var/snap/microk8s/common/var/lib/kubelet/pods/41ff28c8-2a2e-48e7-be23-be8fbc504554/volumes/kubernetes.io~projected/kube-api-access-s8bdb]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/96c08affc86bfc83a6788eefbbc8eec1d6e16de9f453bf63bf01ef6944be3d3f/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.grpc.v1.cri/sandboxes/2a269f6ac78d3076e246eadecdba11318b8279dbd431fc2cf665cc9fda8610a8/shm]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:/proc/meminfo]
	# system ram = yes
	# system swap = auto
	# hardware corrupted ECC = auto
	# committed memory = yes
	# writeback memory = yes
	# kernel memory = yes
	# slab memory = yes
	# hugepages = auto
	# transparent hugepages = auto
	# filename to monitor = /proc/meminfo

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/2a269f6ac78d3076e246eadecdba11318b8279dbd431fc2cf665cc9fda8610a8/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.grpc.v1.cri/sandboxes/f5d3c1020c8af5835c5ecc221017686b892cd0d2833c4732b61d8825a9c44a96/shm]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/f5d3c1020c8af5835c5ecc221017686b892cd0d2833c4732b61d8825a9c44a96/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.grpc.v1.cri/sandboxes/5f28c85fbcfefae3616c19f8bd39162bdf627c8cc53ab972aac51fd7a80aaa80/shm]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/5f28c85fbcfefae3616c19f8bd39162bdf627c8cc53ab972aac51fd7a80aaa80/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/9d48293af1db1602e9bff4c67e6b042799cc7cc3e572bed65e61c376b3d6458d/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/de1be8ca7f1fd5ddc9d53a2ba2b23a70c628fe702eeda227db164b60293f59e0/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/566a6ec2f96e67b4f8ba2855b2405bbd9f2f42e559703d8acdc82d0c3ec46fe1/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/var/snap/microk8s/common/run/containerd/io.containerd.runtime.v2.task/k8s.io/43933ebcdf9ecea6ed9d6ef146df1753b2fd4ad3a024f9643e42954f04c6d90f/rootfs]
	# space usage = no
	# inodes usage = no

[plugin:proc:diskspace:/run/netdata]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:/sys/kernel/mm/ksm]
	# /sys/kernel/mm/ksm/pages_shared = /sys/kernel/mm/ksm/pages_shared
	# /sys/kernel/mm/ksm/pages_sharing = /sys/kernel/mm/ksm/pages_sharing
	# /sys/kernel/mm/ksm/pages_unshared = /sys/kernel/mm/ksm/pages_unshared
	# /sys/kernel/mm/ksm/pages_volatile = /sys/kernel/mm/ksm/pages_volatile

[plugin:proc:/sys/devices/system/edac/mc]
	# directory to monitor = /sys/devices/system/edac/mc

[plugin:proc:/proc/net/wireless]
	# filename to monitor = /proc/net/wireless
	# status for all interfaces = auto
	# quality for all interfaces = auto
	# discarded packets for all interfaces = auto
	# missed beacon for all interface = auto

[plugin:proc:/proc/net/sockstat]
	# ipv4 sockets = auto
	# ipv4 TCP sockets = auto
	# ipv4 TCP memory = auto
	# ipv4 UDP sockets = auto
	# ipv4 UDP memory = auto
	# ipv4 UDPLITE sockets = auto
	# ipv4 RAW sockets = auto
	# ipv4 FRAG sockets = auto
	# ipv4 FRAG memory = auto
	# update constants every = 60
	# filename to monitor = /proc/net/sockstat

[plugin:proc:diskspace:/run/user]
	# space usage = auto
	# inodes usage = auto

[plugin:proc:diskspace:/sys/kernel/debug/tracing]
	# space usage = no
	# inodes usage = no

[plugin:proc:/proc/net/sockstat6]
	# ipv6 TCP sockets = auto
	# ipv6 UDP sockets = auto
	# ipv6 UDPLITE sockets = auto
	# ipv6 RAW sockets = auto
	# ipv6 FRAG sockets = auto
	# filename to monitor = /proc/net/sockstat6

[plugin:proc:/proc/net/netstat]
	# bandwidth = auto
	# input errors = auto
	# multicast bandwidth = auto
	# broadcast bandwidth = auto
	# multicast packets = auto
	# broadcast packets = auto
	# ECN packets = auto
	# TCP reorders = auto
	# TCP SYN cookies = auto
	# TCP out-of-order queue = auto
	# TCP connection aborts = auto
	# TCP memory pressures = auto
	# TCP SYN queue = auto
	# TCP accept queue = auto
	# filename to monitor = /proc/net/netstat

[plugin:proc:/proc/net/snmp]
	# ipv4 packets = auto
	# ipv4 fragments sent = auto
	# ipv4 fragments assembly = auto
	# ipv4 errors = auto
	# ipv4 TCP connections = auto
	# ipv4 TCP packets = auto
	# ipv4 TCP errors = auto
	# ipv4 TCP opens = auto
	# ipv4 TCP handshake issues = auto
	# ipv4 UDP packets = auto
	# ipv4 UDP errors = auto
	# ipv4 ICMP packets = auto
	# ipv4 ICMP messages = auto
	# ipv4 UDPLite packets = auto
	# filename to monitor = /proc/net/snmp

[plugin:proc:/proc/net/snmp6]
	# ipv6 packets = auto
	# ipv6 fragments sent = auto
	# ipv6 fragments assembly = auto
	# ipv6 errors = auto
	# ipv6 UDP packets = auto
	# ipv6 UDP errors = auto
	# ipv6 UDPlite packets = auto
	# ipv6 UDPlite errors = auto
	# bandwidth = auto
	# multicast bandwidth = auto
	# broadcast bandwidth = auto
	# multicast packets = auto
	# icmp = auto
	# icmp redirects = auto
	# icmp errors = auto
	# icmp echos = auto
	# icmp group membership = auto
	# icmp router = auto
	# icmp neighbor = auto
	# icmp mldv2 = auto
	# icmp types = auto
	# ect = auto
	# filename to monitor = /proc/net/snmp6

[plugin:proc:/proc/net/sctp/snmp]
	# established associations = auto
	# association transitions = auto
	# fragmentation = auto
	# packets = auto
	# packet errors = auto
	# chunk types = auto
	# filename to monitor = /proc/net/sctp/snmp

[plugin:proc:/proc/net/softnet_stat]
	# softnet_stat per core = yes
	# filename to monitor = /proc/net/softnet_stat

[plugin:proc:/proc/net/ip_vs_stats]
	# IPVS bandwidth = yes
	# IPVS connections = yes
	# IPVS packets = yes
	# filename to monitor = /proc/net/ip_vs_stats

[plugin:proc:/sys/class/infiniband]
	# dirname to monitor = /sys/class/infiniband
	# bandwidth counters = yes
	# packets counters = yes
	# errors counters = yes
	# hardware packets counters = auto
	# hardware errors counters = auto
	# monitor only active ports = auto
	# disable by default interfaces matching = 
	# refresh ports state every seconds = 30

[plugin:proc:/sys/class/infiniband:mlx5_0-1]
	# bytes = yes
	# packets = yes
	# errors = yes
	# hwpackets = auto
	# hwerrors = auto

[plugin:proc:/proc/net/stat/nf_conntrack]
	# filename to monitor = /proc/net/stat/nf_conntrack
	# netfilter new connections = no
	# netfilter connection changes = no
	# netfilter connection expectations = no
	# netfilter connection searches = no
	# netfilter errors = no
	# netfilter connections = yes

[plugin:proc:/proc/sys/net/netfilter/nf_conntrack_max]
	# filename to monitor = /proc/sys/net/netfilter/nf_conntrack_max
	# read every seconds = 10

[plugin:proc:/proc/sys/net/netfilter/nf_conntrack_count]
	# filename to monitor = /proc/sys/net/netfilter/nf_conntrack_count

[plugin:proc:/proc/net/stat/synproxy]
	# SYNPROXY cookies = auto
	# SYNPROXY SYN received = auto
	# SYNPROXY connections reopened = auto
	# filename to monitor = /proc/net/stat/synproxy

[plugin:proc:/proc/diskstats]
	# enable new disks detected at runtime = yes
	# performance metrics for physical disks = auto
	# performance metrics for virtual disks = auto
	# performance metrics for partitions = no
	# bandwidth for all disks = auto
	# operations for all disks = auto
	# merged operations for all disks = auto
	# i/o time for all disks = auto
	# queued operations for all disks = auto
	# utilization percentage for all disks = auto
	# extended operations for all disks = auto
	# backlog for all disks = auto
	# bcache for all disks = auto
	# bcache priority stats update every = 0
	# remove charts of removed disks = yes
	# path to get block device = /sys/block/%s
	# path to get block device bcache = /sys/block/%s/bcache
	# path to get virtual block device = /sys/devices/virtual/block/%s
	# path to get block device infos = /sys/dev/block/%lu:%lu/%s
	# path to device mapper = /dev/mapper
	# path to /dev/disk/by-label = /dev/disk/by-label
	# path to /dev/disk/by-id = /dev/disk/by-id
	# path to /dev/vx/dsk = /dev/vx/dsk
	# name disks by id = no
	# preferred disk ids = *
	# exclude disks = loop* ram*
	# filename to monitor = /proc/diskstats
	# performance metrics for disks with major 8 = yes

[plugin:proc:/proc/diskstats:loop0]
	# enable = no

[plugin:proc:/proc/diskstats:loop1]
	# enable = no

[plugin:proc:/proc/diskstats:loop2]
	# enable = no

[plugin:proc:/proc/diskstats:loop3]
	# enable = no

[plugin:proc:/proc/diskstats:loop4]
	# enable = no

[plugin:proc:/proc/diskstats:loop5]
	# enable = no

[plugin:proc:/proc/diskstats:loop6]
	# enable = no

[plugin:proc:/proc/diskstats:loop7]
	# enable = no

[plugin:proc:/proc/diskstats:sda]
	# enable = yes
	# enable performance metrics = yes
	# bandwidth = auto
	# operations = auto
	# merged operations = auto
	# i/o time = auto
	# queued operations = auto
	# utilization percentage = auto
	# extended operations = auto
	# backlog = auto

[plugin:proc:/proc/diskstats:cloudimg-rootfs]
	# enable = yes
	# enable performance metrics = no
	# bandwidth = no
	# operations = no
	# merged operations = no
	# i/o time = no
	# queued operations = no
	# utilization percentage = no
	# extended operations = no
	# backlog = no

[plugin:proc:/proc/diskstats:sda14]
	# enable = yes
	# enable performance metrics = no
	# bandwidth = no
	# operations = no
	# merged operations = no
	# i/o time = no
	# queued operations = no
	# utilization percentage = no
	# extended operations = no
	# backlog = no

[plugin:proc:/proc/diskstats:uefi]
	# enable = yes
	# enable performance metrics = no
	# bandwidth = no
	# operations = no
	# merged operations = no
	# i/o time = no
	# queued operations = no
	# utilization percentage = no
	# extended operations = no
	# backlog = no

[plugin:proc:/proc/diskstats:sdb]
	# enable = yes
	# enable performance metrics = yes
	# bandwidth = auto
	# operations = auto
	# merged operations = auto
	# i/o time = auto
	# queued operations = auto
	# utilization percentage = auto
	# extended operations = auto
	# backlog = auto

[plugin:proc:/proc/diskstats:sdb1]
	# enable = yes
	# enable performance metrics = no
	# bandwidth = no
	# operations = no
	# merged operations = no
	# i/o time = no
	# queued operations = no
	# utilization percentage = no
	# extended operations = no
	# backlog = no

[plugin:proc:/proc/mdstat]
	# faulty devices = yes
	# nonredundant arrays availability = yes
	# mismatch count = auto
	# disk stats = yes
	# operation status = yes
	# make charts obsolete = yes
	# filename to monitor = /proc/mdstat
	# mismatch_cnt filename to monitor = /sys/block/%s/md/mismatch_cnt

[plugin:proc:/proc/net/rpc/nfsd]
	# filename to monitor = /proc/net/rpc/nfsd

[plugin:proc:/proc/net/rpc/nfs]
	# filename to monitor = /proc/net/rpc/nfs

[plugin:proc:/proc/spl/kstat/zfs/arcstats]
	# filename to monitor = /proc/spl/kstat/zfs/arcstats

[plugin:proc:/proc/spl/kstat/zfs]
	# directory to monitor = /proc/spl/kstat/zfs

[plugin:proc:/sys/fs/btrfs]
	# path to monitor = /sys/fs/btrfs
	# check for btrfs changes every = 60
	# physical disks allocation = auto
	# data allocation = auto
	# metadata allocation = auto
	# system allocation = auto

[plugin:proc:ipc]
	# message queues = yes
	# semaphore totals = yes
	# shared memory totals = yes
	# msg filename to monitor = /proc/sysvipc/msg
	# shm filename to monitor = /proc/sysvipc/shm
	# max dimensions in memory allowed = 50

[plugin:proc:/sys/class/power_supply]
	# battery capacity = yes
	# battery charge = no
	# battery energy = no
	# power supply voltage = no
	# keep files open = auto
	# directory to monitor = /sys/class/power_supply
